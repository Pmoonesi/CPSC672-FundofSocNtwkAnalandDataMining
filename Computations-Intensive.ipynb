{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c704ce4b-ba19-42cb-8bfa-92b2b8c83b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import networkx as nx\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7edd526-437b-4149-a17b-be4a1f43dc85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_network(filename):\n",
    "    G = nx.read_gml(filename)\n",
    "    G.remove_edges_from(list(nx.selfloop_edges(G)))\n",
    "    G.remove_nodes_from(list(nx.isolates(G)))\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be5494ef-2607-4318-9f0c-0e3a976083cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# orig_filepath = 'Processed/years/average/months/network-1.gml'\n",
    "orig_filepath = 'Processed/years/average/temp/network-temp-4.gml'\n",
    "\n",
    "G = read_network(orig_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0dc53da4-e7e4-4cbf-9e10-22c68909d2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "null_models_pattern = orig_filepath.replace('temp', 'temp_null').replace('.gml', \"-*.gml\")\n",
    "\n",
    "null_models_paths = glob.glob(null_models_pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "641032e0-1ddc-4288-b593-e51a9bb0a3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# null_models = list(map(read_network, null_models_paths))\n",
    "import multiprocessing as mp\n",
    "\n",
    "with mp.Pool() as pool:\n",
    "    null_models = pool.map(read_network, null_models_paths, chunksize=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "847278c3-38b1-46e0-aeb8-40842a8d9d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def arr_to_dict(arr, G):\n",
    "    return dict(zip(list(G.nodes()), arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5fd47433-5fe7-447b-bd31-67d49c12b688",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "def get_pvalue(null_dist, obs_value):\n",
    "    mu = np.mean(null_dist)\n",
    "    sigma = np.std(null_dist, ddof=1)\n",
    "\n",
    "    if sigma == 0:\n",
    "        if mu == obs_value:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "            \n",
    "    z = (obs_value - mu) / sigma\n",
    "    p = 2 * norm.sf(np.abs(z))\n",
    "    return p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c019a6-6475-4e3d-8d9b-79503d0152fe",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## (global) efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30adbf0d-942c-45dc-a098-cb852bd134fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/aestrivex/bctpy/blob/1b40e281eda081060707e30b68106ac1ebf54130/bct/algorithms/distance.py#L107\n",
    "\n",
    "# https://github.com/aestrivex/bctpy/blob/master/bct/algorithms/efficiency.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "69e4552c-93d3-464d-a377-1364e1a8a4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bct.algorithms.efficiency import efficiency_wei\n",
    "from bct.utils.other import weight_conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "868aff19-419a-4cc0-adc0-2d00c25a90c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = nx.to_numpy_array(G, weight='duration_weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "576473a1-c584-4ea2-86f0-47d30fa4c0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "An = weight_conversion(A, 'normalize') # An = A / A.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "a5fbe999-81d9-4929-aef8-2960763765d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_result = efficiency_wei(An, 'global')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eaff625-7de5-430d-a097-bf6c871a4862",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_efficiencies(G):\n",
    "\n",
    "    try:\n",
    "        A = nx.to_numpy_array(G, weight='duration_weights')\n",
    "        An = weight_conversion(A, 'normalize')\n",
    "        return efficiency_wei(An, 'global')\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "\n",
    "with mp.Pool() as pool:\n",
    "    results = pool.map(do_efficiencies, null_models, chunksize=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ed3e4f7-fd03-4086-bbb1-cbcbca0d7c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bct.algorithms.efficiency import efficiency_wei\n",
    "from bct.utils.other import weight_conversion\n",
    "import multiprocessing as mp\n",
    "\n",
    "def do_global_efficiency(G):\n",
    "    try:\n",
    "        A = nx.to_numpy_array(G, weight='duration_weights')\n",
    "        An = weight_conversion(A, 'normalize')\n",
    "        return efficiency_wei(An, 'global')\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "def get_global_efficiency(G, G_nulls):\n",
    "\n",
    "    orig_result = do_global_efficiency(G)\n",
    "\n",
    "    with mp.Pool() as pool:\n",
    "        results = pool.map(do_global_efficiency, null_models, chunksize=1)\n",
    "\n",
    "    return {'orig': orig_result, 'nulls': results}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4cc687ef-ef35-4431-a509-6f32094afc86",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = get_global_efficiency(G, null_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39cb1088-9dca-4960-b85d-62243fbda6cd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## local efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c3e1cbc6-8e94-409a-8059-d17da9fd3e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bct.algorithms.efficiency import efficiency_wei\n",
    "from bct.utils.other import weight_conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6811669f-3396-4015-9568-b82342488de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = nx.to_numpy_array(G, weight='duration_weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c96d1002-0dc7-4205-813e-43387db75a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "An = weight_conversion(A, 'normalize') # An = A / A.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8b4a75c0-96d3-4974-8376-8a89d2bdf595",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_result = efficiency_wei(An, 'local')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c1ac6b68-52ae-4058-903c-29f5020c6b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "from bct.algorithms.efficiency import efficiency_wei\n",
    "from bct.utils.other import weight_conversion\n",
    "\n",
    "def do_local_efficiency(G):\n",
    "\n",
    "    try:\n",
    "        A = nx.to_numpy_array(G, weight='duration_weights')\n",
    "        An = weight_conversion(A, 'normalize') # An = A / A.max()\n",
    "        local_efficiency = efficiency_wei(An, 'local')\n",
    "        return local_efficiency\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "def get_local_efficiency(G, G_nulls):\n",
    "    orig_results = do_local_efficiency(G)\n",
    "    \n",
    "    with mp.Pool() as pool:\n",
    "        results = pool.map(do_local_efficiency, G_nulls, chunksize=1)\n",
    "\n",
    "    results_stacked = np.vstack(results).T\n",
    "\n",
    "    return {'orig': arr_to_dict(orig_results, G), 'nulls': arr_to_dict(results_stacked, G)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3b02367e-b0e2-48a4-9b9f-eeb1a36758a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = do_local_efficiency(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "50b25c58-7eeb-4f28-a7c1-3bc408430783",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(565,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "009478e3-cee9-4b75-9c38-3c3425cff8d9",
   "metadata": {},
   "source": [
    "## motifs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68e17ba6-427b-440a-ba46-466e1d898e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/aestrivex/bctpy/blob/1b40e281eda081060707e30b68106ac1ebf54130/bct/algorithms/motifs.py#L405"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "921084d9-ab35-45f9-bde7-d36ba7331ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bct.algorithms.motifs import motif3struct_wei, make_motif34lib, find_motif34\n",
    "from bct.utils.other import weight_conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8572e084-650e-4dfb-946a-435b3e2a4502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "motif34lib already exists\n"
     ]
    }
   ],
   "source": [
    "make_motif34lib()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e92c5b21-bfe9-4695-8b63-c5d0ef1c25ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = nx.to_numpy_array(G, weight='trip_count_weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "69dc7b7d-b8f8-49fd-bc78-1d1b5a9b3009",
   "metadata": {},
   "outputs": [],
   "source": [
    "An = weight_conversion(A, 'normalize') # An = A / A.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "afe84f77-575d-42d3-862b-a8ef74736dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "I, Q, F = motif3struct_wei(An)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8d02f93a-2295-4b88-8bb3-ff73e3b2831d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_motif_analysis(G):\n",
    "\n",
    "    A = nx.to_numpy_array(G, weight='trip_count_weights')\n",
    "    An = weight_conversion(A, 'normalize') # An = A / A.max()\n",
    "    I, Q, F = motif3struct_wei(An)\n",
    "\n",
    "    return I.T, Q.T, F.T\n",
    "\n",
    "\n",
    "def get_motif_analysis(G, G_nulls):\n",
    "\n",
    "    orig_result_I, orig_result_Q, orig_result_F = do_motif_analysis(G)\n",
    "\n",
    "    with mp.Pool() as pool:\n",
    "        results = pool.map(do_motif_analysis, null_models, chunksize=1)\n",
    "\n",
    "    results_I, results_Q, results_F = zip(*results)\n",
    "\n",
    "    results_stacked_I, results_stacked_Q, results_stacked_F = np.stack(results_I, axis=-1), np.stack(results_Q, axis=-1), np.stack(results_F, axis=-1)\n",
    "\n",
    "    return {'orig': {'I': arr_to_dict(orig_result_I, G),'Q': arr_to_dict(orig_result_Q, G),'F': arr_to_dict(orig_result_F, G)},\n",
    "            'nulls': {'I': arr_to_dict(results_stacked_I, G),'Q': arr_to_dict(results_stacked_Q, G),'F': arr_to_dict(results_stacked_F, G)}}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0558fcee-ae1a-402f-adf9-06d4c14e74d7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## strength centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4425001-e9f0-4a07-b2b6-9ed9a5491f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_strength_centrality(G):\n",
    "    try:\n",
    "        A = nx.to_numpy_array(G, weight='tpd_weights')\n",
    "        istr = np.sum(A, axis=0)\n",
    "        ostr = np.sum(A, axis=1)\n",
    "        return (istr, ostr)\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "def get_strength_centrality(G, G_nulls):\n",
    "\n",
    "    orig_result_in, orig_result_out = do_strength_centrality(G)\n",
    "\n",
    "    with mp.Pool() as pool:\n",
    "        results = pool.map(do_strength_centrality, null_models, chunksize=1)\n",
    "\n",
    "    results_in, results_out = zip(*results)\n",
    "\n",
    "    results_stacked_in, results_stacked_out = np.vstack(results_in).T, np.vstack(results_out).T\n",
    "\n",
    "    return {'orig': {'in': arr_to_dict(orig_result_in, G) ,'out': arr_to_dict(orig_result_out, G)}, 'nulls': {'in': arr_to_dict(results_stacked_in, G),'out': arr_to_dict(results_stacked_out, G)}}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2dbbc1b3-d667-4de8-ae4e-59de1e5e0a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = get_strength_centrality(G, null_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "9a5e3330-fbd7-4fac-923b-1be003b4ddeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "null_result_in, null_result_out = zip(*results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "83c6ccc8-dff7-4265-8080-8820e8623f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "null_strength_in, null_strength_out = np.vstack(null_result_in).T, np.vstack(null_result_out).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "31707b68-dc7a-4b9b-86d3-549a26345c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_values_strength_in = [get_pvalue(null_dist, obs_value) for null_dist, obs_value in list(zip(null_strength_in, orig_result_in))]\n",
    "p_values_strength_out = [get_pvalue(null_dist, obs_value) for null_dist, obs_value in list(zip(null_strength_out, orig_result_out))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "1add92df-ffe5-40dd-9674-4443115bfc35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'7004': 0.2991853933763128,\n",
       " '7245': 0.3550656950544403,\n",
       " '7253': 0.38378785701356843,\n",
       " '7928': 0.41139309416458625,\n",
       " '7045': 0.41931197670767617}"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(sorted(list(zip(list(G.nodes()), p_values_strength_in)), key=lambda item: item[1])[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c57e42f-62cd-47e1-83ad-7494e8090f6e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## eigenvector centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eac528da-b30a-459d-afa6-610f3fc46ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://networkx.org/documentation/stable/reference/algorithms/generated/networkx.algorithms.centrality.eigenvector_centrality.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8096203c-4794-4c7e-86e9-d80e38c67f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "\n",
    "def do_eigenvector_centrality(G):\n",
    "\n",
    "    try:\n",
    "        in_eig = nx.eigenvector_centrality(G, weight='tpd_weights')\n",
    "        out_eig = nx.eigenvector_centrality(G.reverse(), weight='tpd_weights')\n",
    "        return in_eig, out_eig\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "def get_eigenvector_centrality(G, G_nulls):\n",
    "    \n",
    "    orig_result_in, orig_result_out = do_eigenvector_centrality(G)\n",
    "\n",
    "    with mp.Pool() as pool:\n",
    "        results = pool.map(do_eigenvector_centrality, null_models, chunksize=1)\n",
    "\n",
    "    null_result_in, null_result_out = zip(*results)\n",
    "\n",
    "    null_result_in_agg = {}\n",
    "    for k in list(G.nodes()):\n",
    "      null_result_in_agg[k] = list(d[k] for d in null_result_in)\n",
    "    \n",
    "    null_result_out_agg = {}\n",
    "    for k in list(G.nodes()):\n",
    "      null_result_out_agg[k] = list(d[k] for d in null_result_out)\n",
    "\n",
    "    return {'orig': {'in': orig_result_in ,'out': orig_result_out}, 'nulls': {'in': null_result_in_agg,'out': null_result_out_agg}}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5915110f-95fb-4f9e-b658-9040c0cd5779",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = get_eigenvector_centrality(G, null_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d3330219-d27c-4b03-811d-a12dfef84798",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_result_in = nx.eigenvector_centrality(G, weight='tpd_weights')\n",
    "orig_result_out = nx.eigenvector_centrality(G.reverse(), weight='tpd_weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "41248302-51a3-41fe-bac1-214ce72f3ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "null_result_in, null_result_out = zip(*results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "03353f60-7110-4b69-9ac3-7a9aae77dbfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "null_result_in_agg = {}\n",
    "for k in list(G.nodes()):\n",
    "  null_result_in_agg[k] = list(d[k] for d in null_result_in)\n",
    "\n",
    "null_result_out_agg = {}\n",
    "for k in list(G.nodes()):\n",
    "  null_result_out_agg[k] = list(d[k] for d in null_result_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "f6edd08a-d432-4935-9e64-88fc60add2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pvalue_eig_in = dict([(node, get_pvalue(null_result_in_agg[node], orig_result_in[node])) for node in list(G.nodes())])\n",
    "pvalue_eig_out = dict([(node, get_pvalue(null_result_out_agg[node], orig_result_out[node])) for node in list(G.nodes())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "f56cc038-34ba-4a5f-86f4-7eac0f2d7ba3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'7033': 3.443399557134471e-09,\n",
       " '7408': 5.114139007848561e-09,\n",
       " '7017': 6.745208009582761e-09,\n",
       " '7202': 4.931274533195474e-07,\n",
       " '7012': 5.026564061613139e-07}"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(sorted(pvalue_eig_in.items(), key=lambda item: item[1])[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "541ebba0-da09-4d49-ae3f-789e44039d00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'7408': 1.1623695027589606e-07,\n",
       " '7161': 1.452443961699128e-07,\n",
       " '7250': 1.3262246807918202e-06,\n",
       " '7020': 2.4139085705415033e-06,\n",
       " '7012': 3.514325117420618e-06}"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(sorted(pvalue_eig_out.items(), key=lambda item: item[1])[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1490ce4-b9b5-4852-b495-43b4b3fbdbbf",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## betweenness centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "6847e290-cbc8-4a90-b081-3d71e6283a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bct.algorithms.centrality import betweenness_wei\n",
    "from bct.utils.other import weight_conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "4d523f01-9432-4d79-b2a8-7be8257d5664",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = nx.to_numpy_array(G, weight='duration_weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ab178535-dee1-4db4-b7e0-3c169481954c",
   "metadata": {},
   "outputs": [],
   "source": [
    "L = weight_conversion(A, 'lengths')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "787b64af-0bea-4a08-b81e-5bb4cf0848e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "BC = betweenness_wei(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d3729797-c142-4557-a4da-b9aaa8f874a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "from bct.algorithms.centrality import betweenness_wei\n",
    "from bct.utils.other import weight_conversion\n",
    "\n",
    "def do_betweenness_centrality(G):\n",
    "\n",
    "    try:\n",
    "        A = nx.to_numpy_array(G, weight='duration_weights')\n",
    "        L = weight_conversion(A, 'lengths')\n",
    "        BC = betweenness_wei(L)\n",
    "        return BC\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "def get_betweenness_centrality(G, G_nulls):\n",
    "    orig_results = do_betweenness_centrality(G)\n",
    "    \n",
    "    with mp.Pool() as pool:\n",
    "        results = pool.map(do_betweenness_centrality, null_models, chunksize=1)\n",
    "\n",
    "    results_stacked = np.vstack(results).T\n",
    "\n",
    "    return {'orig': arr_to_dict(orig_results, G), 'nulls': arr_to_dict(results_stacked, G)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9d0a5042-19cb-4203-a5a0-3bcca0ce57de",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = get_betweenness_centrality(G, null_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "5fe74a83-2d84-40ba-b87d-3f85586b31df",
   "metadata": {},
   "outputs": [],
   "source": [
    "null_betweenness = np.vstack(results).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "eef3fea3-a3e6-47a2-aee7-4063e339e589",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_values_betweenness = [get_pvalue(null_dist, obs_value) for null_dist, obs_value in list(zip(null_betweenness, BC))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "f5770f65-6c50-476a-966a-3bb3b8e06c2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'7171': 0.0, '7146': 0.0, '7133': 0.0, '7095': 0.0, '7180': 0.0}"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(sorted(list(zip(list(G.nodes()), p_values_betweenness)), key=lambda item: item[1])[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43665b40-5dc5-4077-92b5-9b00e35fbf29",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## all at the same time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6588e4e1-e453-4bb6-ba8a-9451d0cfb13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import networkx as nx\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import multiprocessing as mp\n",
    "from bct.algorithms.centrality import betweenness_wei\n",
    "from bct.algorithms.efficiency import efficiency_wei\n",
    "from bct.utils.other import weight_conversion\n",
    "import sys\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "def read_network(filename):\n",
    "    G = nx.read_gml(filename)\n",
    "    G.remove_edges_from(list(nx.selfloop_edges(G)))\n",
    "    G.remove_nodes_from(list(nx.isolates(G)))\n",
    "    return G\n",
    "\n",
    "def arr_to_dict(arr, G):\n",
    "    return dict(zip(list(G.nodes()), arr))\n",
    "\n",
    "## global efficiency\n",
    "\n",
    "def do_global_efficiency(G):\n",
    "    try:\n",
    "        A = nx.to_numpy_array(G, weight='duration_weights')\n",
    "        An = weight_conversion(A, 'normalize')\n",
    "        return efficiency_wei(An, 'global')\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "def get_global_efficiency(G, G_nulls):\n",
    "\n",
    "    orig_result = do_global_efficiency(G)\n",
    "\n",
    "    with mp.Pool() as pool:\n",
    "        results = pool.map(do_global_efficiency, G_nulls, chunksize=1)\n",
    "\n",
    "    return {'orig': orig_result, 'nulls': results}\n",
    "\n",
    "## strength centrality\n",
    "\n",
    "def do_strength_centrality(G):\n",
    "    try:\n",
    "        A = nx.to_numpy_array(G, weight='tpd_weights')\n",
    "        istr = np.sum(A, axis=0)\n",
    "        ostr = np.sum(A, axis=1)\n",
    "        return (istr, ostr)\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "def get_strength_centrality(G, G_nulls):\n",
    "\n",
    "    orig_result_in, orig_result_out = do_strength_centrality(G)\n",
    "\n",
    "    with mp.Pool() as pool:\n",
    "        results = pool.map(do_strength_centrality, G_nulls, chunksize=1)\n",
    "\n",
    "    results_in, results_out = zip(*results)\n",
    "\n",
    "    results_stacked_in, results_stacked_out = np.vstack(results_in).T, np.vstack(results_out).T\n",
    "\n",
    "    return {'orig': {'in': arr_to_dict(orig_result_in, G) ,'out': arr_to_dict(orig_result_out, G)}, 'nulls': {'in': arr_to_dict(results_stacked_in, G),'out': arr_to_dict(results_stacked_out, G)}}\n",
    "\n",
    "## eigenvector centrality\n",
    "\n",
    "def do_eigenvector_centrality(G):\n",
    "\n",
    "    try:\n",
    "        in_eig = nx.eigenvector_centrality(G, weight='tpd_weights')\n",
    "        out_eig = nx.eigenvector_centrality(G.reverse(), weight='tpd_weights')\n",
    "        return in_eig, out_eig\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "def get_eigenvector_centrality(G, G_nulls):\n",
    "    \n",
    "    orig_result_in, orig_result_out = do_eigenvector_centrality(G)\n",
    "\n",
    "    with mp.Pool() as pool:\n",
    "        results = pool.map(do_eigenvector_centrality, G_nulls, chunksize=1)\n",
    "\n",
    "    null_result_in, null_result_out = zip(*results)\n",
    "\n",
    "    null_result_in_agg = {}\n",
    "    for k in list(G.nodes()):\n",
    "      null_result_in_agg[k] = list(d[k] for d in null_result_in)\n",
    "    \n",
    "    null_result_out_agg = {}\n",
    "    for k in list(G.nodes()):\n",
    "      null_result_out_agg[k] = list(d[k] for d in null_result_out)\n",
    "\n",
    "    return {'orig': {'in': orig_result_in ,'out': orig_result_out}, 'nulls': {'in': null_result_in_agg,'out': null_result_out_agg}}\n",
    "\n",
    "\n",
    "## betweenness centrality\n",
    "\n",
    "def do_betweenness_centrality(G):\n",
    "\n",
    "    try:\n",
    "        A = nx.to_numpy_array(G, weight='duration_weights')\n",
    "        L = weight_conversion(A, 'lengths')\n",
    "        BC = betweenness_wei(L)\n",
    "        return BC\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "def get_betweenness_centrality(G, G_nulls):\n",
    "    orig_results = do_betweenness_centrality(G)\n",
    "    \n",
    "    with mp.Pool() as pool:\n",
    "        results = pool.map(do_betweenness_centrality, G_nulls, chunksize=1)\n",
    "\n",
    "    results_stacked = np.vstack(results).T\n",
    "\n",
    "    return {'orig': arr_to_dict(orig_results, G), 'nulls': arr_to_dict(results_stacked, G)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5034c4bd-c119-411b-a27f-1aab76b0c1ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "years months\n",
      "processing Processed/years/average/months/network-12.gml...\n",
      "members months\n",
      "processing Processed/members/average/months/network-12.gml...\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "pattern = re.compile(r\"Processed\\/([a-z]+)\\/average\\/([a-z]+)\\/.*\\.gml\")\n",
    "\n",
    "## main\n",
    "\n",
    "# usertype = sys.argv[1]\n",
    "# nettype = \"months\"\n",
    "\n",
    "# orig_filepaths = glob.glob(f'Processed/{usertype}/average/{nettype}/*.gml')\n",
    "orig_filepaths = [\"Processed/years/average/months/network-12.gml\", \"Processed/members/average/months/network-12.gml\"]\n",
    "\n",
    "for orig_filepath in orig_filepaths:\n",
    "\n",
    "    usertype, nettype = pattern.match(orig_filepath).group(1), pattern.match(orig_filepath).group(2)\n",
    "    print(usertype, nettype)\n",
    "\n",
    "    print(f\"processing {orig_filepath}...\")\n",
    "\n",
    "    filename = orig_filepath.split('/')[-1].split('.')[0]\n",
    "\n",
    "    G = read_network(orig_filepath)\n",
    "\n",
    "    null_models_pattern = orig_filepath.replace(f'{nettype}', f'{nettype}_null').replace('.gml', \"-*.gml\")\n",
    "\n",
    "    null_models_paths = glob.glob(null_models_pattern)\n",
    "\n",
    "    with mp.Pool() as pool:\n",
    "        null_models = pool.map(read_network, null_models_paths, chunksize=1)\n",
    "\n",
    "    ## global efficiency\n",
    "    ge_filename = os.path.join(f'results/efficiency/global/{usertype}/{nettype}', f'{filename}.pkl')\n",
    "\n",
    "    if not os.path.isfile(ge_filename):\n",
    "\n",
    "        ge = get_global_efficiency(G, null_models)\n",
    "\n",
    "        with open(ge_filename, 'wb') as f:\n",
    "            pickle.dump(ge, f)\n",
    "\n",
    "    ## strength centrality\n",
    "    sc_filename = os.path.join(f'results/centrality/strength/{usertype}/{nettype}', f'{filename}.pkl')\n",
    "\n",
    "    if not os.path.isfile(sc_filename):\n",
    "        \n",
    "        sc = get_strength_centrality(G, null_models)\n",
    "    \n",
    "        with open(sc_filename, 'wb') as f:\n",
    "            pickle.dump(sc, f)\n",
    "\n",
    "    ## eigenvector centrality\n",
    "    ec_filename = os.path.join(f'results/centrality/eigenvector/{usertype}/{nettype}', f'{filename}.pkl')\n",
    "\n",
    "    if not os.path.isfile(ec_filename):\n",
    "        \n",
    "        ec = get_eigenvector_centrality(G, null_models)\n",
    "    \n",
    "        with open(ec_filename, 'wb') as f:\n",
    "            pickle.dump(ec, f)\n",
    "\n",
    "    ## betweenness centrality\n",
    "    bc_filename = os.path.join(f'results/centrality/betweenness/{usertype}/{nettype}', f'{filename}.pkl')\n",
    "\n",
    "    if not os.path.isfile(bc_filename):\n",
    "        \n",
    "        bc = get_betweenness_centrality(G, null_models)\n",
    "    \n",
    "        with open(bc_filename, 'wb') as f:\n",
    "            pickle.dump(bc, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
